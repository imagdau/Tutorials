{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a40121600b3c467da428477bc8bf55e0",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# MACE in Practice II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "95057ab91ce54145b569a1b35cc81742",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "In this tutorial, you will learn how to fit and test a `MACE` model (Message Passing Neural Network), which is a highly accurate and efficient MLIP (Machine Learnt Interatomic Potential). The training/testing techniques we show here, however, are broadly applicable to all MLIPs. You can independently learn about MACE by studying the [original method paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/4a36c3c51af11ed9f34615b81edb5bbc-Paper-Conference.pdf). MACE was developed by unifying the Atomic Cluster Expansion (ACE) approach with the Neural Equivariant Interatomic Potentials (NequIP). The mathematical formalism which unifies these methods is explained in the [accompaning paper](https://doi.org/10.48550/arXiv.2205.06643). Another [useful reference](https://doi.org/10.48550/arXiv.2305.14247) showcases the method's performance on published benchmark datasets. The [code implementation](https://github.com/ACEsuit/mace) is publically available and [here](https://mace-docs.readthedocs.io/en/latest/) you can find the documentation.\n",
    "\n",
    "## Learning Objectives for today:\n",
    "\n",
    "1. **Iterative Training: improving stability and accuracy**\n",
    "2. **Error estimation: committee models**\n",
    "3. **Active learning: unsupervised iterative training**\n",
    "4. **Foundational models: out-of-the-box MLIPs**\n",
    "5. **Fine-tuning on new data and labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6334ee06bcc24a8db4c5a87dfc2d7985",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## The Molecular Liquid Condensed Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bc011009c8a845a7b48ad6f6c4570c39",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The MLIP was trained on clusters, can we simulate the liquid molecular environment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "db474b39ce1c4ba1918219a52c749dd1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 495641,
    "execution_start": 1690389440265,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "init_conf = read('data/ECEMC.xyz','4') #read a liquid config with periodic boundary conditions\n",
    "init_conf.center()\n",
    "\n",
    "simpleMD(init_conf, temp=500, calc=mace_calc, fname='liquid_md.xyz', s=10, T=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bfa824eb023047b0ab1ce1d1754e1430",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "This XTB calculator is non-periodic, so this dynamics would not be possible without an MLIP! Check for yourself, by replacing the calculator with xtb. The system is much larger than the example before (12 molecules vs just one), check how GAP scales with size by replacing the calculator with gap.\n",
    "\n",
    "\n",
    "Transferability from clusters to the condensed phase environment is still an open research question. If this works, it implies that we might be able to learn on highly accuracte Quantum Chemistry methods on molecular clusters and make predictions (density, diffusivity) for the condensed phase! This is new Science!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a00c92d61afc4adcb493f1cc7b2ee3a6",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Active Learning with MACE\n",
    "\n",
    "This is a short tutorial on how to use active learning with MACE.\n",
    "\n",
    "Active learning consists is an iterative fitting process aiming at providing the model with the most optimal training data for increasing its performance. For any active learning sheme, two things are essential:\n",
    "\n",
    "- A efficient data generation source, in our case molecular dynamics.\n",
    "- A score function rating the utility of a given data to be trained\n",
    "\n",
    "The score function in the case of interatomic potentials is usually correlated to the uncertainty of the prediction of the model for a given configuration. For neural networks potentials like MACE, a straightforward measure of uncertainty is the variance of the output over an ensemble of models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "588eeeda5dc94c76841aba2af1c4f90a",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "To obtain a comittee from MACE, we need to train a committee of models and add some randomness to the optimization process. We can achieve this by changing the `--seed`.\n",
    "\n",
    "Let us train three small MACE models to make sure they break for demo purposes. We will use different seeds for the three independent models. This will allow us to create a `comittee` of independent predictors. As we change hyper parameters, we will also change the `--name` of the model to make sure it saves seperatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "37e61d6c0e554372a743359ba7f4b567",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 389976,
    "execution_start": 1690389935772,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "#prepare a much smaller training example, and let us pick independent data sets\n",
    "from ase.io import read, write\n",
    "db = read('data/solvent_xtb.xyz', ':')\n",
    "write('data/solvent_mace_small1_train.xyz', db[:3]+db[3:53]) #\n",
    "write('data/solvent_mace_small2_train.xyz', db[:3]+db[53:103])\n",
    "write('data/solvent_mace_small3_train.xyz', db[:3]+db[103:153])\n",
    "\n",
    "#train the first model\n",
    "!python3 ./mace/scripts/run_train.py \\\n",
    "    --name=\"model_small1\" \\\n",
    "    --train_file=\"data/solvent_mace_small1_train.xyz\" \\\n",
    "    --valid_fraction=0.05 \\\n",
    "    --E0s=\"isolated\" \\\n",
    "    --energy_key=\"energy\" \\\n",
    "    --forces_key=\"forces\" \\\n",
    "    --model=\"MACE\" \\\n",
    "    --num_interactions=2 \\\n",
    "    --max_ell=2 \\\n",
    "    --hidden_irreps=\"16x0e\" \\\n",
    "    --num_cutoff_basis=5 \\\n",
    "    --correlation=2 \\\n",
    "    --r_max=3.0 \\\n",
    "    --batch_size=5 \\\n",
    "    --valid_batch_size=5 \\\n",
    "    --eval_interval=1 \\\n",
    "    --max_num_epochs=50 \\\n",
    "    --start_swa=30 \\\n",
    "    --swa_energy_weight=1000 \\\n",
    "    --ema \\\n",
    "    --ema_decay=0.99 \\\n",
    "    --amsgrad \\\n",
    "    --error_table=\"PerAtomRMSE\" \\\n",
    "    --default_dtype=\"float32\" \\\n",
    "    --swa \\\n",
    "    --device=cuda \\\n",
    "    --seed=345\n",
    "\n",
    "#train the second model\n",
    "!python3 ./mace/scripts/run_train.py \\\n",
    "    --name=\"model_small2\" \\\n",
    "    --train_file=\"data/solvent_mace_small2_train.xyz\" \\\n",
    "    --valid_fraction=0.05 \\\n",
    "    --E0s=\"isolated\" \\\n",
    "    --energy_key=\"energy\" \\\n",
    "    --forces_key=\"forces\" \\\n",
    "    --model=\"MACE\" \\\n",
    "    --num_interactions=2 \\\n",
    "    --max_ell=2 \\\n",
    "    --hidden_irreps=\"16x0e\" \\\n",
    "    --num_cutoff_basis=5 \\\n",
    "    --correlation=2 \\\n",
    "    --r_max=3.0 \\\n",
    "    --batch_size=5 \\\n",
    "    --valid_batch_size=5 \\\n",
    "    --eval_interval=1 \\\n",
    "    --max_num_epochs=50 \\\n",
    "    --start_swa=30 \\\n",
    "    --swa_energy_weight=1000 \\\n",
    "    --ema \\\n",
    "    --ema_decay=0.99 \\\n",
    "    --amsgrad \\\n",
    "    --error_table=\"PerAtomRMSE\" \\\n",
    "    --default_dtype=\"float32\" \\\n",
    "    --swa \\\n",
    "    --device=cuda \\\n",
    "    --seed=567\n",
    "\n",
    "#train the thirds model\n",
    "!python3 ./mace/scripts/run_train.py \\\n",
    "    --name=\"model_small3\" \\\n",
    "    --train_file=\"data/solvent_mace_small3_train.xyz\" \\\n",
    "    --valid_fraction=0.05 \\\n",
    "    --E0s=\"isolated\" \\\n",
    "    --energy_key=\"energy\" \\\n",
    "    --forces_key=\"forces\" \\\n",
    "    --model=\"MACE\" \\\n",
    "    --num_interactions=2 \\\n",
    "    --max_ell=2 \\\n",
    "    --hidden_irreps=\"16x0e\" \\\n",
    "    --num_cutoff_basis=5 \\\n",
    "    --correlation=2 \\\n",
    "    --r_max=3.0 \\\n",
    "    --batch_size=5 \\\n",
    "    --valid_batch_size=5 \\\n",
    "    --eval_interval=1 \\\n",
    "    --max_num_epochs=50 \\\n",
    "    --start_swa=30 \\\n",
    "    --swa_energy_weight=1000 \\\n",
    "    --ema \\\n",
    "    --ema_decay=0.99 \\\n",
    "    --amsgrad \\\n",
    "    --error_table=\"PerAtomRMSE\" \\\n",
    "    --default_dtype=\"float32\" \\\n",
    "    --swa \\\n",
    "    --device=cuda \\\n",
    "    --seed=731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ec2e91aa94044d14aeadea824b5fecbe",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Now we can run dynamics with a commitee of models and look at the variance in the energy prediction. Because XTB is cheap enough we can compare that variance with the true error. Do they correlate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "763720f0e2ed4ea7a27db276507b4fa9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 741598,
    "execution_start": 1690390325607,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "from aseMolec import extAtoms as ea\n",
    "from ase import units\n",
    "from ase.md.langevin import Langevin\n",
    "from ase.md.velocitydistribution import Stationary, ZeroRotation, MaxwellBoltzmannDistribution\n",
    "from ase.io import read, write\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "\n",
    "from xtb.ase.calculator import XTB\n",
    "from mace.calculators import MACECalculator\n",
    "\n",
    "model_paths = ['model_small1_swa.model','model_small2_swa.model', 'model_small3_swa.model']\n",
    "xtb_calc = XTB(method=\"GFN2-xTB\")\n",
    "mace_calc = MACECalculator(model_paths=model_paths, device='cpu', default_dtype=\"float32\")\n",
    "\n",
    "init_conf = ea.sel_by_info_val(read('data/solvent_molecs.xyz',':'), 'Nmols', 1)[0].copy()\n",
    "init_conf.set_calculator(mace_calc)\n",
    "\n",
    "#initialize the temperature\n",
    "random.seed(701)\n",
    "MaxwellBoltzmannDistribution(init_conf, temperature_K=500)\n",
    "Stationary(init_conf)\n",
    "ZeroRotation(init_conf)\n",
    "\n",
    "dyn = Langevin(init_conf, 1*units.fs, temperature_K=1200, friction=0.1)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "time_fs = []\n",
    "temperature = []\n",
    "energies_1 = []\n",
    "energies_2 = []\n",
    "energies_3 = []\n",
    "variances = []\n",
    "xtb_energies = []\n",
    "true_errors = []\n",
    "\n",
    "! rm -rfv committee_md.xyz\n",
    "fig, ax = pl.subplots(3, 1, figsize=(8,8), sharex='all', gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "\n",
    "\n",
    "def write_frame():\n",
    "        at = dyn.atoms.copy()\n",
    "        at.calc = xtb_calc\n",
    "        xtb_energy = at.get_potential_energy()\n",
    "\n",
    "        dyn.atoms.write('committee_md.xyz', append=True)\n",
    "        time_fs.append(dyn.get_time()/units.fs)\n",
    "        temperature.append(dyn.atoms.get_temperature())\n",
    "        energies_1.append(dyn.atoms.calc.results[\"energies\"][0]/len(dyn.atoms))\n",
    "        energies_2.append(dyn.atoms.calc.results[\"energies\"][1]/len(dyn.atoms))\n",
    "        energies_3.append(dyn.atoms.calc.results[\"energies\"][2]/len(dyn.atoms))\n",
    "        variances.append(dyn.atoms.calc.results[\"energy_var\"]/len(dyn.atoms))\n",
    "        xtb_energies.append(xtb_energy/len(dyn.atoms))\n",
    "        true_errors.append(np.var([dyn.atoms.calc.results[\"energy\"],xtb_energy])/len(dyn.atoms))\n",
    "\n",
    "        # subplot the variance of the energy as a function of the steps and the temperature as two subplots\n",
    "        ax[0].plot(np.array(time_fs), np.array(variances), color=\"y\")\n",
    "        ax[0].plot(np.array(time_fs), np.array(true_errors), color=\"black\")\n",
    "        ax[0].set_ylabel(r'$\\Delta$ E (eV$^2$/atom)')\n",
    "        ax[0].legend(['Estimated Error', 'True Error'], loc='lower left')\n",
    "\n",
    "        # plot the temperature of the system as subplots\n",
    "        ax[1].plot(np.array(time_fs), temperature, color=\"r\", label='Temperature')\n",
    "        ax[1].set_ylabel(\"T (K)\")\n",
    "\n",
    "        ax[2].plot(np.array(time_fs), energies_1, color=\"g\")\n",
    "        ax[2].plot(np.array(time_fs), energies_2, color=\"y\")\n",
    "        ax[2].plot(np.array(time_fs), energies_3, color=\"olive\")\n",
    "        ax[2].plot(np.array(time_fs), xtb_energies, color=\"black\")\n",
    "        ax[2].set_ylabel(\"E (eV/atom)\")\n",
    "        ax[2].set_xlabel('Time (fs)')\n",
    "        ax[2].legend(['E mace1', 'E mace2', 'E mace3', 'E xtb'], loc='lower left')\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(fig)\n",
    "        time.sleep(0.01)\n",
    "\n",
    "dyn.attach(write_frame, interval=10)\n",
    "dyn.run(2000)\n",
    "print(\"MD finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "742910790a0d4f1fa1d187c5e9d5de70",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "As expected, the dynamics has failed. In this case our reference PES is xtb which is cheap to evaluate so we can easily check the error on the fly. In practice we will be trainking MLIPs on expensive reference methods, where computing the true error on the fly is impractical. Notice when the dynamics `explodes`, the `true error` divergese, but crucially the `estimated error` also diverges."
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "2a16e1e8a7ad42a8825007f5cff15d19",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
